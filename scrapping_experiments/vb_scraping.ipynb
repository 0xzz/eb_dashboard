{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime\n",
    "import json\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    return page.status_code, soup\n",
    "\n",
    "def get_date(soup, d, country_name, table_id=2, eb_id=1):\n",
    "    tables = []\n",
    "    for tb in soup.find_all('table'):\n",
    "        rows = tb.find_all('tr')\n",
    "        if len(rows)>3:\n",
    "            data = []\n",
    "            for row in rows:\n",
    "                cols = row.find_all('td')\n",
    "                cols = [ele.text.strip() for ele in cols]\n",
    "                data.append([ele for ele in cols if ele])\n",
    "            tables.append(data)\n",
    "    \n",
    "    wanted_table = tables[table_id]\n",
    "    country_list = [c.replace('\\n ','').lower() for c in wanted_table[0]]\n",
    "    country_name = country_name.lower()\n",
    "    country_ind = [i for i,c in enumerate(country_list) if country_name in c]\n",
    "    country_id = country_ind[0]\n",
    "    res = wanted_table[eb_id][country_id]\n",
    "    \n",
    "    if res=='C':\n",
    "        res_d = d\n",
    "    elif res=='U':\n",
    "        res_d = ''\n",
    "    else:\n",
    "        DD = int(res[:2])\n",
    "        MON = res[2:5]\n",
    "        YYYY = 2000+int(res[-2:])\n",
    "        if YYYY>2030:\n",
    "            YYYY-=1000\n",
    "        MM = M_abbr.index(MON)+1\n",
    "        res_d = datetime.date(YYYY,MM,DD)\n",
    "    return res_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "M=['january','february','march','april','may','june','july','august','september','october','november','december']\n",
    "M_abbr = [a[:3].upper() for a in M]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-10-01   2015-10-01 2015-10-01 2015-10-01\n",
      "2015-11-01   2015-11-01 2015-11-01 2015-11-01\n",
      "2015-12-01   2015-12-01 2015-12-01 2015-12-01\n",
      "2016-01-01   2016-01-01 2016-01-01 2016-01-01\n",
      "2016-02-01   2016-02-01 2016-02-01 2016-02-01\n",
      "2016-03-01   2016-03-01 2016-03-01 2016-03-01\n",
      "2016-04-01   2016-04-01 2016-04-01 2016-04-01\n",
      "2016-05-01   2016-05-01 2016-05-01 2016-05-01\n",
      "2016-06-01   2016-06-01 2016-06-01 2016-06-01\n",
      "2016-07-01   2016-07-01 2016-07-01 2016-07-01\n",
      "2016-08-01   2016-08-01 2010-01-01 2010-01-01\n",
      "2016-09-01   2016-09-01 2010-01-01 2010-01-01\n",
      "2016-10-01   2016-10-01 2016-10-01 2016-10-01\n",
      "2016-11-01   2016-11-01 2016-11-01 2016-11-01\n",
      "2016-12-01   2016-12-01 2016-12-01 2016-12-01\n",
      "2017-01-01   2017-01-01 2017-01-01 2017-01-01\n",
      "2017-02-01   2017-02-01 2017-02-01 2017-02-01\n",
      "2017-03-01   2017-03-01 2017-03-01 2017-03-01\n",
      "2017-04-01   2017-04-01 2017-04-01 2017-04-01\n",
      "2017-05-01   2017-05-01 2017-05-01 2017-05-01\n",
      "2017-06-01   2017-06-01 2012-01-01 2012-01-01\n",
      "2017-07-01   2017-07-01 2012-01-01 2012-01-01\n",
      "2017-08-01   2017-08-01 2012-01-01 2012-01-01\n",
      "2017-09-01   2017-09-01 2012-01-01 2012-01-01\n",
      "2017-10-01   2017-10-01 2017-10-01 2017-10-01\n",
      "2017-11-01   2017-11-01 2017-11-01 2017-11-01\n",
      "2017-12-01   2017-12-01 2017-12-01 2017-12-01\n",
      "2018-01-01   2018-01-01 2018-01-01 2018-01-01\n",
      "2018-02-01   2018-02-01 2018-02-01 2018-02-01\n",
      "2018-03-01   2018-03-01 2018-03-01 2018-03-01\n",
      "2018-04-01   2018-04-01 2012-01-01 2012-01-01\n",
      "2018-05-01   2018-05-01 2012-01-01 2012-01-01\n",
      "2018-06-01   2018-06-01 2012-01-01 2012-01-01\n",
      "2018-07-01   2018-07-01 2012-01-01 2012-01-01\n",
      "2018-08-01   2016-05-01 2012-01-01 2012-01-01\n",
      "2018-09-01   2016-06-01 2012-01-01 2012-01-01\n",
      "2018-10-01   2017-04-01 2016-06-01 2016-06-01\n",
      "2018-11-01   2017-04-01 2016-06-01 2016-06-01\n",
      "2018-12-01   2017-07-01 2016-09-01 2016-09-01\n",
      "2019-01-01   2017-10-01 2016-12-15 2016-12-15\n",
      "2019-02-01   2017-12-01 2017-02-08 2017-02-08\n",
      "2019-03-01   2018-01-01 2017-02-22 2017-02-22\n",
      "2019-04-01   2018-02-01 2017-02-22 2017-02-22\n",
      "2019-05-01   2018-03-01 2017-02-22 2017-02-22\n",
      "2019-06-01   2018-04-22 2017-02-22 2015-01-01\n",
      "2019-07-01   2018-04-22 2017-05-08 2015-01-01\n",
      "2019-08-01   2016-07-01 2016-07-01 2015-01-01\n",
      "2019-09-01   2017-10-01 2014-01-01 \n",
      "2019-10-01   2018-04-22 2016-11-01 2015-01-01\n",
      "2019-11-01   2018-06-01 2017-02-01 2015-01-01\n",
      "2019-12-01   2018-07-15 2017-05-15 2015-01-01\n",
      "2020-01-01   2018-10-01 2017-05-22 2015-01-01\n",
      "2020-02-01   2018-12-01 2017-05-22 2015-01-01\n"
     ]
    }
   ],
   "source": [
    "x1 = []\n",
    "row_days1 = []\n",
    "cn_days1 = []\n",
    "in_days1 = []\n",
    "\n",
    "for yr in [2015, 2016, 2017, 2018, 2019, 2020]:\n",
    "    bd, ed = 0, 12\n",
    "    if yr==2015:\n",
    "        bd=9\n",
    "    if yr==2020:\n",
    "        ed=2\n",
    "    for i in range(bd, 12):\n",
    "        m = M[i]\n",
    "        fy = yr if i<9 else yr+1\n",
    "        url = f'https://travel.state.gov/content/travel/en/legal/visa-law0/visa-bulletin/{fy}/visa-bulletin-for-{m}-{yr}.html'\n",
    "        s, soup = get_soup(url)\n",
    "        if s==404:\n",
    "            url = f'https://travel.state.gov/content/travel/en/legal/visa-law0/visa-bulletin/{fy}/visa-bulletin-{m}-{yr}.html'\n",
    "            s, soup = get_soup(url)            \n",
    "        \n",
    "        d = datetime.date(yr, i+1, 1)\n",
    "\n",
    "        try:\n",
    "            res_ROW   = get_date(soup,d,'all', table_id=2, eb_id=eb_id)\n",
    "            res_CHINA = get_date(soup,d,'china', table_id=2, eb_id=eb_id)\n",
    "            res_INDIA = get_date(soup,d,'india', table_id=2, eb_id=eb_id)\n",
    "        except:\n",
    "            break\n",
    "            \n",
    "        x1.append(d)\n",
    "        row_days1.append(res_ROW)\n",
    "        cn_days1.append(res_CHINA)\n",
    "        in_days1.append(res_INDIA)\n",
    "        \n",
    "        print(d,' ',res_ROW, res_CHINA, res_INDIA)\n",
    "    #break\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2007-01-01   2007-01-01 2005-04-22 2003-01-08\n",
      "2008-01-01   2008-01-01 2003-01-01 2000-01-01\n",
      "2008-02-01   2008-02-01 2003-01-01 \n",
      "2008-03-01   2008-03-01 2003-12-01 \n",
      "2008-04-01   2008-04-01 2003-12-01 2003-12-01\n",
      "2008-05-01   2008-05-01 2004-01-01 2004-01-01\n",
      "2008-06-01   2008-06-01 2004-04-01 2004-04-01\n",
      "2008-07-01   2008-07-01 2004-04-01 2004-04-01\n",
      "2008-08-01   2008-08-01 2006-06-01 2006-06-01\n",
      "2008-09-01   2008-09-01 2006-08-01 2006-08-01\n",
      "2008-10-01   2008-10-01 2004-04-01 2003-04-01\n",
      "2008-11-01   2008-11-01 2004-06-01 2003-06-01\n",
      "2008-12-01   2008-12-01 2004-06-01 2003-06-01\n",
      "2009-01-01   2009-01-01 2004-07-08 2003-07-01\n",
      "2009-02-01   2009-02-01 2005-01-01 2004-01-01\n",
      "2009-03-01   2009-03-01 2005-02-15 2004-02-15\n",
      "2009-04-01   2009-04-01 2005-02-15 2004-02-15\n",
      "2009-05-01   2009-05-01 2005-02-15 2004-02-15\n",
      "2009-06-01   2009-06-01 2005-02-15 2000-01-01\n",
      "2010-01-01   2010-01-01 2005-05-01 2005-01-22\n",
      "2010-02-01   2010-02-01 2005-05-22 2005-01-22\n",
      "2010-03-01   2010-03-01 2005-07-08 2005-02-01\n",
      "2010-04-01   2010-04-01 2005-08-22 2005-02-01\n",
      "2010-05-01   2010-05-01 2005-09-22 2005-02-01\n",
      "2010-06-01   2010-06-01 2005-11-22 2005-02-01\n",
      "2010-07-01   2010-07-01 2005-11-22 2005-10-01\n",
      "2010-08-01   2010-08-01 2006-03-01 2006-03-01\n",
      "2010-09-01   2010-09-01 2006-05-08 2006-05-08\n",
      "2010-10-01   2010-10-01 2006-05-22 2006-05-08\n",
      "2010-11-01   2010-11-01 2006-06-01 2006-05-08\n",
      "2010-12-01   2010-12-01 2006-06-08 2006-05-08\n",
      "2011-01-01   2011-01-01 2006-06-22 2006-05-08\n",
      "2011-02-01   2011-02-01 2006-07-01 2006-05-08\n",
      "2011-03-01   2011-03-01 2006-07-08 2006-05-08\n",
      "2011-04-01   2011-04-01 2006-07-22 2006-05-08\n",
      "2011-05-01   2011-05-01 2006-08-01 2006-07-01\n",
      "2011-06-01   2011-06-01 2006-10-15 2006-10-15\n",
      "2011-07-01   2011-07-01 2007-03-08 2007-03-08\n",
      "2011-08-01   2011-08-01 2007-04-15 2007-04-15\n",
      "2011-09-01   2011-09-01 2007-04-15 2007-04-15\n",
      "2011-10-01   2011-10-01 2007-07-15 2007-07-15\n",
      "2011-11-01   2011-11-01 2007-11-01 2007-11-01\n",
      "2011-12-01   2011-12-01 2008-03-15 2008-03-15\n",
      "2012-01-01   2012-01-01 2009-01-01 2009-01-01\n",
      "2012-02-01   2012-02-01 2010-01-01 2010-01-01\n",
      "2012-03-01   2012-03-01 2010-05-01 2010-05-01\n",
      "2012-04-01   2012-04-01 2010-05-01 2010-05-01\n",
      "2012-05-01   2012-05-01 2007-08-15 2007-08-15\n",
      "2012-06-01   2012-06-01  \n",
      "2012-07-01   2009-01-01  \n",
      "2012-08-01   2009-01-01  \n",
      "2012-09-01   2009-01-01  \n",
      "2012-10-01   2012-01-01 2007-07-15 2004-09-01\n",
      "2012-11-01   2012-11-01 2007-09-01 2004-09-01\n",
      "2012-12-01   2012-12-01 2007-10-22 2004-09-01\n",
      "2013-01-01   2013-01-01 2007-12-08 2004-09-01\n",
      "2013-02-01   2013-02-01 2008-01-15 2004-09-01\n",
      "2013-03-01   2013-03-01 2008-02-15 2004-09-01\n",
      "2013-04-01   2013-04-01 2008-04-01 2004-09-01\n",
      "2013-05-01   2013-05-01 2008-05-15 2004-09-01\n",
      "2013-06-01   2013-06-01 2008-07-15 2004-09-01\n",
      "2013-07-01   2013-07-01 2008-08-08 2004-09-01\n",
      "2013-08-01   2013-08-01 2008-08-08 2008-01-01\n",
      "2013-09-01   2013-09-01 2008-08-08 2008-06-15\n",
      "2013-10-01   2013-10-01 2008-09-15 2008-06-15\n",
      "2013-11-01   2013-11-01 2008-10-08 2008-06-15\n",
      "2013-12-01   2013-12-01 2008-11-08 2004-11-15\n",
      "2014-01-01   2014-01-01 2008-12-08 2004-11-15\n",
      "2014-02-01   2014-02-01 2009-01-08 2004-11-15\n",
      "2014-03-01   2014-03-01 2009-02-15 2004-11-15\n",
      "2014-04-01   2014-04-01 2009-03-08 2004-11-15\n",
      "2014-05-01   2014-05-01 2009-04-15 2004-11-15\n",
      "2014-06-01   2014-06-01 2009-05-22 2004-11-15\n",
      "2014-07-01   2014-07-01 2009-07-01 2008-09-01\n",
      "2014-08-01   2014-08-01 2009-10-08 2009-01-22\n",
      "2014-09-01   2014-09-01 2009-10-08 2009-05-01\n",
      "2014-10-01   2014-10-01 2009-11-15 2009-05-01\n",
      "2014-11-01   2014-11-01 2009-12-08 2005-02-15\n",
      "2014-12-01   2014-12-01 2010-01-01 2005-02-15\n",
      "2015-01-01   2015-01-01 2010-02-01 2005-02-15\n",
      "2015-02-01   2015-02-01 2010-03-15 2005-09-01\n",
      "2015-03-01   2015-03-01 2010-09-01 2007-01-01\n",
      "2015-04-01   2015-04-01 2011-04-01 2007-09-01\n",
      "2015-05-01   2015-05-01 2012-06-01 2008-04-15\n",
      "2015-06-01   2015-06-01 2013-06-01 2008-10-01\n",
      "2015-07-01   2015-07-01 2013-10-01 2008-10-01\n",
      "2015-08-01   2015-08-01 2013-12-15 2008-10-01\n",
      "2015-09-01   2015-09-01 2006-01-01 2006-01-01\n"
     ]
    }
   ],
   "source": [
    "x0 = []\n",
    "row_days0 = []\n",
    "cn_days0 = []\n",
    "in_days0 = []\n",
    "\n",
    "for yr in range(2004,2016):\n",
    "    if yr==2015:\n",
    "        ed=9\n",
    "    else:\n",
    "        ed=12\n",
    "    for i in range(0,ed):\n",
    "        m = M[i]\n",
    "        fy = yr if i<9 else yr+1\n",
    "        url = f'https://travel.state.gov/content/travel/en/legal/visa-law0/visa-bulletin/{fy}/visa-bulletin-for-{m}-{yr}.html'\n",
    "        s, soup = get_soup(url)\n",
    "        if s==404:\n",
    "            url = f'https://travel.state.gov/content/travel/en/legal/visa-law0/visa-bulletin/{fy}/visa-bulletin-{m}-{yr}.html'\n",
    "            s, soup = get_soup(url)            \n",
    "\n",
    "        d = datetime.date(yr, i+1, 1)\n",
    "\n",
    "        try:\n",
    "            res_ROW   = get_date(soup,d,'all', table_id=1, eb_id=eb_id)\n",
    "            res_CHINA = get_date(soup,d,'china', table_id=1, eb_id=eb_id)\n",
    "            res_INDIA = get_date(soup,d,'india', table_id=1, eb_id=eb_id)\n",
    "        except:\n",
    "            break\n",
    "            \n",
    "        x0.append(d)\n",
    "        row_days0.append(res_ROW)\n",
    "        cn_days0.append(res_CHINA)\n",
    "        in_days0.append(res_INDIA)\n",
    "        \n",
    "        print(d,' ',res_ROW, res_CHINA, res_INDIA)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=x0+x1\n",
    "row_days = row_days0+row_days1\n",
    "cn_days = cn_days0+cn_days1\n",
    "in_days = in_days0+in_days1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb_fa = {'date':x,\n",
    "          f'eb{eb_id}-row':row_days,\n",
    "          f'eb{eb_id}-cn':cn_days,\n",
    "          f'eb{eb_id}-in':in_days}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(eb_fa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f'./../data/eb{eb_id}_final_action_days.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'eb{eb_id}_fa.pk', 'wb') as f:\n",
    "    pickle.dump(eb_fa,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "plt.plot_date(x,x,':',xdate = True, ydate=True,label='current date')\n",
    "plt.plot_date(x,row_days,'s-',xdate = True, ydate=True,label='Rest of World')\n",
    "plt.plot_date(x,cn_days,'o-',xdate = True, ydate=True,label='China')\n",
    "plt.plot_date(x,in_days,'.-',xdate = True, ydate=True,label='India')\n",
    "#plt.plot_date([datetime.date(2019,11,1),datetime.date(2020,2,1)],[datetime.date(2018,6,1),datetime.date(2018,12,1)],':',color='#ee7700')\n",
    "#plt.plot_date([datetime.date(2019,11,1),datetime.date(2020,2,1)],[datetime.date(2017,2,1),datetime.date(2017,8,1)],':',color='green')\n",
    "#plt.plot_date([datetime.date(2019,11,1),datetime.date(2020,2,1)],[datetime.date(2015,1,1),datetime.date(2015,1,1)],':',color='red')\n",
    "\n",
    "ylim = [datetime.date(1998,8,1),datetime.date(2021,2,1)]\n",
    "xlim = [datetime.date(2003,8,1),datetime.date(2020,2,1)]\n",
    "\n",
    "plt.ylim(ylim)\n",
    "plt.xlim(xlim)\n",
    "plt.grid('on')\n",
    "plt.legend()\n",
    "#plt.title('Estimation of Xiang''s time line')\n",
    "#plt.title('EB1 catastrophe. Table B')\n",
    "plt.title(f'EB{eb_id} Final Action Date')\n",
    "\n",
    "#plt.plot_date([datetime.date(2017,5,30),datetime.date(2017,5,30)],ylim,'k:')\n",
    "#plt.plot_date(xlim,[datetime.date(2017,5,30),datetime.date(2017,5,30)],'k:')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'eb1_fa.pk', 'rb') as f:\n",
    "    eb1_fa = pickle.load(f)\n",
    "with open(f'eb2_fa.pk', 'rb') as f:\n",
    "    eb2_fa = pickle.load(f)\n",
    "with open(f'eb3_fa.pk', 'rb') as f:\n",
    "    eb3_fa = pickle.load(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "plt.plot_date(eb1_fa['x'],eb1_fa['x'],':',xdate = True, ydate=True,label='current')\n",
    "plt.plot_date(eb1_fa['x'],eb1_fa['cn'],'s-',xdate = True, ydate=True,label='EB1-China')\n",
    "plt.plot_date(eb2_fa['x'],eb2_fa['cn'],'o-',xdate = True, ydate=True,label='EB2-China')\n",
    "plt.plot_date(eb3_fa['x'],eb3_fa['cn'],'d-',xdate = True, ydate=True,label='EB3-China')\n",
    "\n",
    "ylim = [datetime.date(1998,8,1),datetime.date(2021,2,1)]\n",
    "xlim = [datetime.date(2003,8,1),datetime.date(2020,2,1)]\n",
    "\n",
    "plt.ylim(ylim)\n",
    "plt.xlim(xlim)\n",
    "plt.grid('on')\n",
    "plt.legend()\n",
    "#plt.title('Estimation of Xiang''s time line')\n",
    "#plt.title('EB1 catastrophe. Table B')\n",
    "plt.title(f'China EB Final Action Date')\n",
    "\n",
    "#plt.plot_date([datetime.date(2017,5,30),datetime.date(2017,5,30)],ylim,'k:')\n",
    "#plt.plot_date(xlim,[datetime.date(2017,5,30),datetime.date(2017,5,30)],'k:')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
